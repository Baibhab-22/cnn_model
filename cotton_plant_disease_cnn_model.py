# -*- coding: utf-8 -*-
"""Cotton Plant Disease CNN Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EmOqE2a8w3VH3Sv-xdWNiY1hGly7_aKC
"""

# Important libraries
import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint

#for Accuracy and Loss Graph
import matplotlib.pyplot as plt

keras.__version__

train_data_path = '/content/drive/MyDrive/dataset/train'
validation_data_path = '/content/drive/MyDrive/dataset/val'

# show augmented images
def plotimages1(images_arr):
  fig, axes = plt.subplot(2,1, figsize=(20,20))
  axes = axes.flatten()
  for img, ax in zip(images_arr,axes):
    ax.imshow(img)

  plt.tight.layout()
  plt.show()

# this is image augmentation configuration we will use for training
training_data= keras.utils.image_dataset_from_directory(train_data_path,
                                                         labels='inferred',
                                                         label_mode='int',
                                                         class_names=None,
                                                         color_mode='rgb',
                                                         batch_size=32,
                                                         image_size=(150, 150),
                                                         shuffle=True,
                                                         seed=123,
                                                         validation_split=0.2,
                                                         subset='training',
                                                         interpolation='bilinear',
                                                         follow_links=False,
                                                         crop_to_aspect_ratio=False)

# training_data = training_data_gen.flow_from_directory(train_data_path,
#                                                       target_size=(150,150),
#                                                       batch_size=32,
#                                                       class_mode='binary')

class_name  = training_data.class_names
class_name

# this is the augmentation configuration we will use for validation
# only rescaling
valid_data = keras.utils.image_dataset_from_directory(validation_data_path,
                                                      image_size=(150,150),
                                                      subset='validation',
                                                      validation_split=0.2,
                                                      seed=123,
                                                      batch_size=32,)

#plot images
plt.figure(figsize=(10, 10))
for images, labels in training_data.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_name[labels[i]])
    plt.axis("off")

"""# **Convolutional Neural Network (CNN) Model Building**"""

model = keras.models.Sequential([
                        keras.layers.Conv2D(filters=32, kernel_size=3, input_shape=[150, 150, 3]),
                        keras.layers.MaxPooling2D(pool_size=(2,2)),
                        keras.layers.Conv2D(filters=64, kernel_size=3),
                        keras.layers.MaxPooling2D(pool_size=(2,2)),
                        keras.layers.Conv2D(filters=128, kernel_size=3),
                        keras.layers.MaxPooling2D(pool_size=(2,2)),
                        keras.layers.Conv2D(filters=256, kernel_size=3),
                        keras.layers.MaxPooling2D(pool_size=(2,2)),

                        keras.layers.Dropout(0,5),
                        keras.layers.Flatten(),  # Neural Network Building
                        keras.layers.Dense(units=128, activation='relu'), # input layer
                        keras.layers.Dropout(0.1),
                        keras.layers.Dense(units=256, activation='relu'),
                        keras.layers.Dropout(0.25),
                        keras.layers.Dense(units=4, activation='softmax')  # Output layer
    ])

model.compile(optimizer=Adam(learning_rate=0.0001), loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])

model.summary()

# save best model using vall accuracy
model_path = '/content/drive/MyDrive/dataset/cotton_plant_disease/pred_cotton_plant_disease_cnn_model.h5'
checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

# Train cnn model
history = model.fit(training_data,
                    epochs=500,
                    verbose=1,
                    validation_data = valid_data,
                    callbacks=callbacks_list)

# shape of images
for image_batch,labels_batch in training_data:
  print(image_batch.shape,labels_batch.shape)
  break

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy',color='green')
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.legend(['train','test'],loc='lower right')
plt.show()

print(history.history['loss'])

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss',color='red',fontsize=15)
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train','test'],loc='upper right')
plt.show()

model.save('nt/drive/MyDrive/dataset/manual_save_model/pred_cotton_plant_disease_cnn_model.h5')

# predict img

model = keras.models.load_model('/content/drive/MyDrive/dataset/cotton_plant_disease/pred_cotton_plant_disease_cnn_model.h5')

import numpy as np

def get_give(img_path):
  test_img = keras.utils.load_img(img_path,target_size=(150,150))
  # after loading img give for np array conversion and normalize
  test_img = keras.utils.img_to_array(test_img)/255
  test_img = np.expand_dims(test_img,axis=0) #chenge dimensions 3D to 4D

  # predict image
  result = model.predict(test_img)
  pred = np.argmax(result)  # get the index of max value

  if pred==0:
    return 'healthy Cotton plant', 'healthy_leaf.html'  # index 0 for burned leaf
  elif pred==1:
    return 'disease cotton plant', 'disease.html'     # index 1 for disease plant
  elif pred==2:
    return 'healthy cotton plant', 'healthy.html'     # index 2 for healthy plant
  else:
    return 'healthy cotton plant','healthy.html'



get_give('/content/drive/MyDrive/dataset/test/diseased cotton plant/dd (706).jpg')

import joblib

joblib.dump(model,'/content/drive/MyDrive/dataset/pic_mod.pkl')
joblib.dump(model,'/content/drive/MyDrive/dataset/pic_mod.joblib')